{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Introduction to TensorFlow \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " After installing and configuring tensorflow, in this Notebook the we will be able to execute examples already seen in the slides. \n",
    "\n",
    " At the end of each section there is a series of exercises wich will familiarize yourself with the most basic syntax seen in these examples before you start to do more complex things. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  TensorFlow Core \n",
    "\n",
    " TensorFlow Core is the lowest level API of TensorFlow, it allows us to have more control over the models. Although there are higher level APIs that can greatly facilitate some tasks. \n",
    "\n",
    " We can see the TensorFlow Core programs as a succession of two steps: \n",
    "1.  Build the computational graph. \n",
    "2.  Execute the computational graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  First we import TensorFlow \n",
    "\n",
    " This gives Python access to all the classes, methods and symbols defined in TensorFlow. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CristeamCaiolaPasqui\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  1) Build the computational graph \n",
    "\n",
    " A computational graph is a series of TensorFlow operations arranged in a graph of nodes. We are going to build a simple computational graph. Each node takes zero or more tensors as inputs and produces a tensor as output. \n",
    "\n",
    " A type of node are the constants (tf.constant). The TensorFlow constants do not take inputs, and produce a value that they store internally. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix1:  Tensor(\"Const:0\", shape=(1, 2), dtype=float32)\n",
      "matrix2:  Tensor(\"Const_1:0\", shape=(2, 1), dtype=float32)\n",
      "product:  Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[1., 1.]], tf.float32) # We can specify the type of a tensor in this way\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "# When printing the nodes of the computational graph we can see that the value is not printed, just the type\n",
    "print(\"matrix1: \", matrix1)\n",
    "print(\"matrix2: \", matrix2)\n",
    "print(\"product: \", product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  2) Execute the computational graph. \n",
    "\n",
    " The following code creates a session object and then invokes its run method to execute the computational graph to evaluate the value of the nodes matrix1 and matrix2. We execute the computational graph in a session in the following way: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1.]], dtype=float32), array([[2.],\n",
       "        [2.]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([matrix1, matrix2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " If we pass a node to a session, it will calculate all the previous graph nodes needed to calculate this node. Let's calculate the product between these two constant matrices: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(product):  [[4.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"sess.run(product): \",sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Finally we close the session: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " We can also make use of the the Python \"with\" statement so the session closes automatically upon finishing the \"with\" block: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(product):  [[4.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"sess.run(product): \",sess.run(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  Choice of the device where the session will be executed \n",
    "\n",
    " We can choose the device that will be used to calculate the operations of the graph. \n",
    "\n",
    " \"/cpu:0\", \"/cpu:1\"... correspond to the different CPUs of our machine (although in a typical computer we usually only have one) \n",
    "\n",
    " \"/gpu:0\", \"/gpu:1\"... correspond to the different GPUs of our machine (although in a typical computer we usually only have one or even none) \n",
    "\n",
    " To be able to use the GPUs, a version of tensorflow that supports this functionality must be installed, and also you must have compatible graphics cards, and install their divers, CUDA, CUDNN... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(product):  [[4.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        print(\"sess.run(product): \",sess.run(product))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <font color=\"red\"> Student Exercise 1:  </font> \n",
    "\n",
    " Build a graph with two constant nodes (scalars or matrices, whichever you prefer) and declare an op that is the result of the sum of both of them. Calculate the result, specifying explicitly that the calculations will be made in the first CPU of the system. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3752114249351331012]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  Placeholders \n",
    "\n",
    " As seen in the slides, a placeholder allows the values of the tensors to be entered directly in any operation of the graph. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([14.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <font color=\"red\">Student Exercise 2:</font> \n",
    "\n",
    " Create an op within the computational graph whose entries are two placeholders, and calculate the module (rest of the division) of the first between the second. Define a session and run that op on it, entering two matrices as input for those placeholders. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.], dtype=float32)]\n",
      "[array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputA = tf.placeholder(tf.float32)\n",
    "inputB = tf.placeholder(tf.float32)\n",
    "output = tf.mod(inputA, inputB)\n",
    "tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output],feed_dict ={inputA:[7.], inputB:[2.]}))\n",
    "    print(sess.run([output],feed_dict ={inputA:[8.], inputB:[2.]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  Variables \n",
    "\n",
    " In machine learning, we usually want a model that is able to take arbitrary inputs. In order for the model to be trained, we must be able to modify the graph to obtain new outputs with the same input. The variables allow us to add trainable parameters to a graph. They are built with a type and an initial value (if type is not specified it is automatically inferred): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for i in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <font color=\"red\"> Student Exercise 3: </font> \n",
    "\n",
    " Using variables, create an op that updates the value of a variable, multiplying it x2 each time. Initialize it to 1, and create a loop that updates its value, until it is equal to 8. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "state = tf.Variable(1, name=\"counter\") \n",
    "two = tf.constant(2) \n",
    "new_value = tf.multiply(state, two) \n",
    "update = tf.assign(state, new_value) \n",
    "init_op = tf.global_variables_initializer() \n",
    "with tf.Session() as sess: \n",
    "    sess.run(init_op) \n",
    "    for _ in range(3): \n",
    "        sess.run(update) \n",
    "    print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-da7799b0e0aa>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-da7799b0e0aa>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    quiz 1 solved\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([3.5], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputA = tf.placeholder(tf.float32)\n",
    "inputB = tf.placeholder(tf.float32)\n",
    "output = tf.divide(inputA, inputB)\n",
    "tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output],feed_dict ={inputA:[7.], inputB:[2.]}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
