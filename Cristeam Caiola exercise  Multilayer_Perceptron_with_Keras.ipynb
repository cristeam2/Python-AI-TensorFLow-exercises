{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cristeam Caiola \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "- excel file provided in online course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load data\n",
    "X_train = np.loadtxt('w4_train_data.csv', delimiter=',', skiprows=1)\n",
    "y_train= np.loadtxt('w4_train_data - y.csv', delimiter=',', skiprows=1) \n",
    "X_test= np.loadtxt(\"w4_test_data.csv\", delimiter=',', skiprows=1)\n",
    "y_test = np.loadtxt(\"w4_test_data - y.csv\", delimiter=',', skiprows=1)\n",
    "print(\"------------------------------------------------------- \")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Keras model object can be created with Sequential class\n",
    "- At the outset, the model is empty per se. It is completed by **'adding'** additional layers and compilation\n",
    "- Doc: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (784,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.2))                        # Dropout layer after Activation\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.2))                        # Dropout layer after Activation\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.2))                        # Dropout layer after Activation\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "#model.add(Dense(10, input_shape = (784,), activation = 'sigmoid'))\n",
    "#model.add(Dense(10, activation = 'sigmoid'))\n",
    "#model.add(Dense(10, activation = 'sigmoid'))\n",
    "#model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimazer\n",
    "sgd = optimizers.SGD(lr = 0.001)    # stochastic gradient descent optimizer\n",
    "#adam = optimizers.Adam(lr = 0.001)    # use Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile of model\n",
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed\n",
    "#model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 8,201\n",
      "Trainable params: 8,141\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20580/20580 [==============================] - 1s 53us/step - loss: 10.4405 - mse: 10.4405\n",
      "Epoch 2/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 4.3572 - mse: 4.3572\n",
      "Epoch 3/100\n",
      "20580/20580 [==============================] - 1s 35us/step - loss: 3.6751 - mse: 3.6751\n",
      "Epoch 4/100\n",
      "20580/20580 [==============================] - 1s 37us/step - loss: 3.3572 - mse: 3.3572\n",
      "Epoch 5/100\n",
      "20580/20580 [==============================] - 1s 38us/step - loss: 3.1486 - mse: 3.1486\n",
      "Epoch 6/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 2.9952 - mse: 2.9952\n",
      "Epoch 7/100\n",
      "20580/20580 [==============================] - 1s 35us/step - loss: 2.8162 - mse: 2.8162\n",
      "Epoch 8/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 2.7329 - mse: 2.7329\n",
      "Epoch 9/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 2.6316 - mse: 2.6316\n",
      "Epoch 10/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 2.5470 - mse: 2.5470\n",
      "Epoch 11/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 2.4805 - mse: 2.4805\n",
      "Epoch 12/100\n",
      "20580/20580 [==============================] - 1s 35us/step - loss: 2.4046 - mse: 2.4046\n",
      "Epoch 13/100\n",
      "20580/20580 [==============================] - 1s 31us/step - loss: 2.3304 - mse: 2.3304\n",
      "Epoch 14/100\n",
      "20580/20580 [==============================] - 1s 35us/step - loss: 2.2928 - mse: 2.2928\n",
      "Epoch 15/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 2.2348 - mse: 2.2348\n",
      "Epoch 16/100\n",
      "20580/20580 [==============================] - 1s 31us/step - loss: 2.1698 - mse: 2.1698\n",
      "Epoch 17/100\n",
      "20580/20580 [==============================] - 1s 31us/step - loss: 2.1106 - mse: 2.1106\n",
      "Epoch 18/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 2.0590 - mse: 2.0590\n",
      "Epoch 19/100\n",
      "20580/20580 [==============================] - 1s 38us/step - loss: 2.0039 - mse: 2.0039\n",
      "Epoch 20/100\n",
      "20580/20580 [==============================] - 1s 38us/step - loss: 1.9748 - mse: 1.9748\n",
      "Epoch 21/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.8921 - mse: 1.8921\n",
      "Epoch 22/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 1.8644 - mse: 1.8644\n",
      "Epoch 23/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.8122 - mse: 1.8122\n",
      "Epoch 24/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.7808 - mse: 1.7808\n",
      "Epoch 25/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 1.7192 - mse: 1.7192\n",
      "Epoch 26/100\n",
      "20580/20580 [==============================] - 1s 38us/step - loss: 1.7327 - mse: 1.7327\n",
      "Epoch 27/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.7065 - mse: 1.7065\n",
      "Epoch 28/100\n",
      "20580/20580 [==============================] - 1s 31us/step - loss: 1.6587 - mse: 1.6587\n",
      "Epoch 29/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.6749 - mse: 1.6749\n",
      "Epoch 30/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.6286 - mse: 1.6286\n",
      "Epoch 31/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.5995 - mse: 1.5995\n",
      "Epoch 32/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.5930 - mse: 1.5930\n",
      "Epoch 33/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.5706 - mse: 1.5706\n",
      "Epoch 34/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.5553 - mse: 1.5553\n",
      "Epoch 35/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.5111 - mse: 1.5111\n",
      "Epoch 36/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.4908 - mse: 1.4908\n",
      "Epoch 37/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.4951 - mse: 1.4951\n",
      "Epoch 38/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.4663 - mse: 1.4663\n",
      "Epoch 39/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.4455 - mse: 1.4455\n",
      "Epoch 40/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.4358 - mse: 1.4358\n",
      "Epoch 41/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.4272 - mse: 1.4272\n",
      "Epoch 42/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.3982 - mse: 1.3982\n",
      "Epoch 43/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.4170 - mse: 1.4170\n",
      "Epoch 44/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.3583 - mse: 1.3583\n",
      "Epoch 45/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.3911 - mse: 1.3911\n",
      "Epoch 46/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.3523 - mse: 1.3523\n",
      "Epoch 47/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.3555 - mse: 1.3555\n",
      "Epoch 48/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.3323 - mse: 1.3323\n",
      "Epoch 49/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.3602 - mse: 1.3602\n",
      "Epoch 50/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.3066 - mse: 1.3066\n",
      "Epoch 51/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.2937 - mse: 1.2937\n",
      "Epoch 52/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.2725 - mse: 1.2725\n",
      "Epoch 53/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.2548 - mse: 1.2548: 0s - loss: 1.2208 -\n",
      "Epoch 54/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.2603 - mse: 1.2603\n",
      "Epoch 55/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.2413 - mse: 1.2413\n",
      "Epoch 56/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.2303 - mse: 1.2303\n",
      "Epoch 57/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.2466 - mse: 1.2466\n",
      "Epoch 58/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.2112 - mse: 1.2112\n",
      "Epoch 59/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.2162 - mse: 1.2163\n",
      "Epoch 60/100\n",
      "20580/20580 [==============================] - 1s 35us/step - loss: 1.2112 - mse: 1.2112\n",
      "Epoch 61/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.1843 - mse: 1.1843\n",
      "Epoch 62/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.2110 - mse: 1.2110\n",
      "Epoch 63/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.1909 - mse: 1.1909\n",
      "Epoch 64/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.1935 - mse: 1.1935\n",
      "Epoch 65/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.1689 - mse: 1.1689\n",
      "Epoch 66/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.1584 - mse: 1.1584\n",
      "Epoch 67/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.1687 - mse: 1.1687\n",
      "Epoch 68/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.1356 - mse: 1.1356\n",
      "Epoch 69/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.1338 - mse: 1.1338\n",
      "Epoch 70/100\n",
      "20580/20580 [==============================] - 1s 35us/step - loss: 1.1528 - mse: 1.1528\n",
      "Epoch 71/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 1.1270 - mse: 1.1270\n",
      "Epoch 72/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.1390 - mse: 1.1390\n",
      "Epoch 73/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.1136 - mse: 1.1136\n",
      "Epoch 74/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.1093 - mse: 1.1093\n",
      "Epoch 75/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.0916 - mse: 1.0916\n",
      "Epoch 76/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.0849 - mse: 1.0849\n",
      "Epoch 77/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.0860 - mse: 1.0860\n",
      "Epoch 78/100\n",
      "20580/20580 [==============================] - 1s 32us/step - loss: 1.0989 - mse: 1.0989\n",
      "Epoch 79/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.0928 - mse: 1.0928\n",
      "Epoch 80/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 1.0852 - mse: 1.0852\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.0876 - mse: 1.0876\n",
      "Epoch 82/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 1.1032 - mse: 1.1032\n",
      "Epoch 83/100\n",
      "20580/20580 [==============================] - 1s 37us/step - loss: 1.0702 - mse: 1.0702\n",
      "Epoch 84/100\n",
      "20580/20580 [==============================] - 1s 36us/step - loss: 1.0570 - mse: 1.0570\n",
      "Epoch 85/100\n",
      "20580/20580 [==============================] - 1s 35us/step - loss: 1.0659 - mse: 1.0659\n",
      "Epoch 86/100\n",
      "20580/20580 [==============================] - 1s 40us/step - loss: 1.0671 - mse: 1.0671\n",
      "Epoch 87/100\n",
      "20580/20580 [==============================] - 1s 50us/step - loss: 1.0508 - mse: 1.0508\n",
      "Epoch 88/100\n",
      "20580/20580 [==============================] - 1s 50us/step - loss: 1.0276 - mse: 1.0276\n",
      "Epoch 89/100\n",
      "20580/20580 [==============================] - 1s 49us/step - loss: 1.0151 - mse: 1.0151\n",
      "Epoch 90/100\n",
      "20580/20580 [==============================] - 1s 42us/step - loss: 1.0319 - mse: 1.0319\n",
      "Epoch 91/100\n",
      "20580/20580 [==============================] - 1s 38us/step - loss: 1.0299 - mse: 1.0299\n",
      "Epoch 92/100\n",
      "20580/20580 [==============================] - 1s 38us/step - loss: 1.0213 - mse: 1.0213\n",
      "Epoch 93/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.0260 - mse: 1.0260\n",
      "Epoch 94/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.0210 - mse: 1.0210\n",
      "Epoch 95/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 1.0238 - mse: 1.0238\n",
      "Epoch 96/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 0.9865 - mse: 0.9865\n",
      "Epoch 97/100\n",
      "20580/20580 [==============================] - 1s 34us/step - loss: 0.9735 - mse: 0.9735\n",
      "Epoch 98/100\n",
      "20580/20580 [==============================] - 1s 35us/step - loss: 0.9974 - mse: 0.9974\n",
      "Epoch 99/100\n",
      "20580/20580 [==============================] - 1s 37us/step - loss: 1.0073 - mse: 1.0073\n",
      "Epoch 100/100\n",
      "20580/20580 [==============================] - 1s 33us/step - loss: 0.9865 - mse: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a4835fbef0>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8820/8820 [==============================] - 0s 37us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mse']\n",
      "[1.0298939371595577, 1.0298937559127808]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1.0298939371595577\n",
      "mse:  1.0298937559127808\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results \n",
    "\n",
    "<b>1-without optimization and SGD=0.01: <br></b>\n",
    "<u>-Training:</u> <br>\n",
    "Epoch 100/100 60000/60000 [==============================] - 1s 22us/step - loss: 3.5553 - mse: 3.5553\n",
    "        \n",
    "<u>-Evaluation:</u><br>\n",
    "loss:  3.2445113330841067\n",
    "mse:  3.244511604309082\n",
    "\n",
    "<b>2-with Dropout and SGD = 0.01</b><br>\n",
    "<u>-Training: </u><br>\n",
    "Epoch 100/100\n",
    " 60000/60000 [==============================] - 2s 30us/step - loss: 8.3513 - mse: 8.3513\n",
    "\n",
    "<u>-Evaluation:</u><br>\n",
    "loss:  8.386413145446777<br>\n",
    "mse:  8.386411666870117\n",
    "\n",
    "<b>3-with Dropout and SGD = 0.001</b><br>\n",
    "<u>-Training: </u><br>\n",
    "Epoch 100/100 29400/29400 [==============================] - 1s 29us/step - loss: 3.0107 - mse: 3.0107\n",
    "\n",
    "<u>-Evaluation:</u><br>\n",
    "loss:  2.0790235421771093<br>\n",
    "mse:  2.0790231227874756\n",
    "\n",
    "<b>4-With Batch Normalization</b><br>\n",
    "<u>-Training: </u><br>\n",
    "Epoch 100/100 20580/20580 [==============================] - 1s 33us/step - loss: 0.9865 - mse: 0.9864\n",
    "\n",
    "<u>-Evaluation:</u><br>\n",
    "loss:  1.0298939371595577 <br>\n",
    "mse:  1.0298937559127808\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for classification tasks\n",
    "- When the target (**y**) is discrete (categorical)\n",
    "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.3, random_state = 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
    "- 30 attributes (features) to predict the binary class (M/B)\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14406, 784)\n",
      "(6174, 784)\n",
      "(14406,)\n",
      "(6174,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Same with regression model at the outset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- It should be noted that as this is a classification problem, sigmoid layer (softmax for multi-class problems) should be added\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (784,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "model.add(Activation('sigmoid'))\n",
    "#odel.add(Dropout(0.2))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "model.add(Activation('sigmoid'))\n",
    "#odel.add(Dropout(0.2))                        # Dropout layer after Activation\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "model.add(Activation('sigmoid'))\n",
    "#odel.add(Dropout(0.2))                        # Dropout layer after Activation\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "#model.add(Dense(10, input_shape = (784,), activation = 'sigmoid'))\n",
    "#model.add(Dense(10, activation = 'sigmoid'))\n",
    "#model.add(Dense(10, activation = 'sigmoid'))\n",
    "#model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.001)    # stochastic gradient descent optimizer\n",
    "#adam = optimizers.Adam(lr = 0.001)    # use Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,201\n",
      "Trainable params: 8,141\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14406/14406 [==============================] - 1s 63us/step - loss: -7.2544 - accuracy: 0.1127\n",
      "Epoch 2/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -23.5853 - accuracy: 0.1092\n",
      "Epoch 3/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -43.9062 - accuracy: 0.1092\n",
      "Epoch 4/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -69.7902 - accuracy: 0.1092\n",
      "Epoch 5/100\n",
      "14406/14406 [==============================] - 1s 42us/step - loss: -100.2065 - accuracy: 0.1092\n",
      "Epoch 6/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -133.8898 - accuracy: 0.1092\n",
      "Epoch 7/100\n",
      "14406/14406 [==============================] - 1s 40us/step - loss: -170.1446 - accuracy: 0.1092\n",
      "Epoch 8/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -207.9028 - accuracy: 0.1092\n",
      "Epoch 9/100\n",
      "14406/14406 [==============================] - 1s 39us/step - loss: -246.3727 - accuracy: 0.1092\n",
      "Epoch 10/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -285.2616 - accuracy: 0.1092\n",
      "Epoch 11/100\n",
      "14406/14406 [==============================] - 0s 33us/step - loss: -324.5154 - accuracy: 0.1092\n",
      "Epoch 12/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -364.0591 - accuracy: 0.1092\n",
      "Epoch 13/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -403.9395 - accuracy: 0.1092\n",
      "Epoch 14/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -443.0116 - accuracy: 0.1092\n",
      "Epoch 15/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -483.1410 - accuracy: 0.1092\n",
      "Epoch 16/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -522.6510 - accuracy: 0.1092\n",
      "Epoch 17/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -562.7509 - accuracy: 0.1092\n",
      "Epoch 18/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -602.3867 - accuracy: 0.1092\n",
      "Epoch 19/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -641.4947 - accuracy: 0.1092\n",
      "Epoch 20/100\n",
      "14406/14406 [==============================] - 0s 33us/step - loss: -681.5629 - accuracy: 0.1092\n",
      "Epoch 21/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -720.6944 - accuracy: 0.1092\n",
      "Epoch 22/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -760.9698 - accuracy: 0.1092\n",
      "Epoch 23/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -800.6464 - accuracy: 0.1092\n",
      "Epoch 24/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -839.7070 - accuracy: 0.1092\n",
      "Epoch 25/100\n",
      "14406/14406 [==============================] - 1s 39us/step - loss: -871.6806 - accuracy: 0.1092\n",
      "Epoch 26/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -916.2854 - accuracy: 0.1092\n",
      "Epoch 27/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -955.3434 - accuracy: 0.1092\n",
      "Epoch 28/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -995.4220 - accuracy: 0.1092\n",
      "Epoch 29/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -1035.2564 - accuracy: 0.1092\n",
      "Epoch 30/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -1075.6654 - accuracy: 0.1092\n",
      "Epoch 31/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -1115.7964 - accuracy: 0.1092\n",
      "Epoch 32/100\n",
      "14406/14406 [==============================] - 1s 39us/step - loss: -1154.3687 - accuracy: 0.1092\n",
      "Epoch 33/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -1194.2545 - accuracy: 0.1092\n",
      "Epoch 34/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -1234.0331 - accuracy: 0.1092\n",
      "Epoch 35/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -1274.0587 - accuracy: 0.1092\n",
      "Epoch 36/100\n",
      "14406/14406 [==============================] - 1s 40us/step - loss: -1314.3883 - accuracy: 0.1092\n",
      "Epoch 37/100\n",
      "14406/14406 [==============================] - 1s 39us/step - loss: -1353.7015 - accuracy: 0.1092\n",
      "Epoch 38/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -1394.3414 - accuracy: 0.1092\n",
      "Epoch 39/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -1432.7535 - accuracy: 0.1092\n",
      "Epoch 40/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -1472.7021 - accuracy: 0.1092\n",
      "Epoch 41/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -1513.4179 - accuracy: 0.1092\n",
      "Epoch 42/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -1552.9021 - accuracy: 0.1092\n",
      "Epoch 43/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -1592.9121 - accuracy: 0.1092\n",
      "Epoch 44/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -1633.0013 - accuracy: 0.1092\n",
      "Epoch 45/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -1672.6289 - accuracy: 0.1092\n",
      "Epoch 46/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -1712.5789 - accuracy: 0.1092\n",
      "Epoch 47/100\n",
      "14406/14406 [==============================] - 0s 35us/step - loss: -1752.0915 - accuracy: 0.1092\n",
      "Epoch 48/100\n",
      "14406/14406 [==============================] - 1s 40us/step - loss: -1792.0923 - accuracy: 0.1092\n",
      "Epoch 49/100\n",
      "14406/14406 [==============================] - 1s 39us/step - loss: -1831.9107 - accuracy: 0.1092\n",
      "Epoch 50/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -1871.6117 - accuracy: 0.1092\n",
      "Epoch 51/100\n",
      "14406/14406 [==============================] - 1s 39us/step - loss: -1910.3661 - accuracy: 0.1092\n",
      "Epoch 52/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -1950.8532 - accuracy: 0.1092\n",
      "Epoch 53/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -1990.9689 - accuracy: 0.1092\n",
      "Epoch 54/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -2030.1967 - accuracy: 0.1092\n",
      "Epoch 55/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -2069.9307 - accuracy: 0.1092\n",
      "Epoch 56/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2111.0492 - accuracy: 0.1092\n",
      "Epoch 57/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2143.7286 - accuracy: 0.1092\n",
      "Epoch 58/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2187.2981 - accuracy: 0.1092\n",
      "Epoch 59/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2229.0324 - accuracy: 0.1092\n",
      "Epoch 60/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2267.1879 - accuracy: 0.1092\n",
      "Epoch 61/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -2309.4957 - accuracy: 0.1092\n",
      "Epoch 62/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -2349.6687 - accuracy: 0.1092\n",
      "Epoch 63/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -2388.5279 - accuracy: 0.1092\n",
      "Epoch 64/100\n",
      "14406/14406 [==============================] - 0s 35us/step - loss: -2427.6028 - accuracy: 0.1092\n",
      "Epoch 65/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -2469.3132 - accuracy: 0.1092\n",
      "Epoch 66/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2509.8803 - accuracy: 0.1092\n",
      "Epoch 67/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -2547.7853 - accuracy: 0.1092\n",
      "Epoch 68/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -2587.8089 - accuracy: 0.1092\n",
      "Epoch 69/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2628.1454 - accuracy: 0.1092\n",
      "Epoch 70/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2668.1372 - accuracy: 0.1092\n",
      "Epoch 71/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -2708.5971 - accuracy: 0.1092\n",
      "Epoch 72/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2747.0738 - accuracy: 0.1092\n",
      "Epoch 73/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -2788.5387 - accuracy: 0.1092\n",
      "Epoch 74/100\n",
      "14406/14406 [==============================] - 1s 39us/step - loss: -2829.1206 - accuracy: 0.1092\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14406/14406 [==============================] - 1s 36us/step - loss: -2868.8289 - accuracy: 0.1092\n",
      "Epoch 76/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -2908.3583 - accuracy: 0.1092\n",
      "Epoch 77/100\n",
      "14406/14406 [==============================] - 1s 39us/step - loss: -2948.0674 - accuracy: 0.1092\n",
      "Epoch 78/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -2987.8762 - accuracy: 0.1092\n",
      "Epoch 79/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -3027.3646 - accuracy: 0.1092\n",
      "Epoch 80/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -3063.6032 - accuracy: 0.1092\n",
      "Epoch 81/100\n",
      "14406/14406 [==============================] - 0s 35us/step - loss: -3090.5192 - accuracy: 0.1092\n",
      "Epoch 82/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -3145.5962 - accuracy: 0.1092\n",
      "Epoch 83/100\n",
      "14406/14406 [==============================] - 0s 35us/step - loss: -3186.4306 - accuracy: 0.1092\n",
      "Epoch 84/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -3227.7615 - accuracy: 0.1092\n",
      "Epoch 85/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -3265.4738 - accuracy: 0.1092\n",
      "Epoch 86/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -3303.6708 - accuracy: 0.1092\n",
      "Epoch 87/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -3346.6497 - accuracy: 0.1092\n",
      "Epoch 88/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -3386.4792 - accuracy: 0.1092\n",
      "Epoch 89/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -3427.3104 - accuracy: 0.1092\n",
      "Epoch 90/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -3466.9967 - accuracy: 0.1092\n",
      "Epoch 91/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -3500.5095 - accuracy: 0.1092\n",
      "Epoch 92/100\n",
      "14406/14406 [==============================] - 0s 34us/step - loss: -3546.8821 - accuracy: 0.1092\n",
      "Epoch 93/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -3585.5374 - accuracy: 0.1092\n",
      "Epoch 94/100\n",
      "14406/14406 [==============================] - 0s 35us/step - loss: -3624.6630 - accuracy: 0.1092\n",
      "Epoch 95/100\n",
      "14406/14406 [==============================] - 0s 35us/step - loss: -3666.0382 - accuracy: 0.1092\n",
      "Epoch 96/100\n",
      "14406/14406 [==============================] - 1s 37us/step - loss: -3705.9063 - accuracy: 0.1092\n",
      "Epoch 97/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -3746.5217 - accuracy: 0.1092\n",
      "Epoch 98/100\n",
      "14406/14406 [==============================] - 1s 38us/step - loss: -3786.5902 - accuracy: 0.1092\n",
      "Epoch 99/100\n",
      "14406/14406 [==============================] - 1s 35us/step - loss: -3824.1012 - accuracy: 0.1092\n",
      "Epoch 100/100\n",
      "14406/14406 [==============================] - 1s 36us/step - loss: -3865.8678 - accuracy: 0.1092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a4819eb9e8>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6174/6174 [==============================] - 0s 46us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "[-3879.7241630887847, 0.11305474489927292]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  -3879.7241630887847\n",
      "accuracy:  0.11305474489927292\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "<b>1-without optimization: </b><br> \n",
    "<u>Training:</u> <br>\n",
    "Epoch 100/100 \n",
    "42000/42000 [==============================] - 1s 28us/step - loss: -109484.1585 - accuracy: 0.1118\n",
    "\n",
    "<u>Evaluation:</u><br>\n",
    "loss:  -110271.03106944445\n",
    "accuracy:  0.11366666853427887\n",
    "\n",
    "<b>2-with Dropout and SGD = 0,01</b><br>\n",
    "<u>Training:</u> <br>\n",
    "Epoch 100/100\n",
    "29400/29400 [==============================] - 1s 31us/step - loss: -77036.9652 - accuracy: 0.1102\n",
    "    \n",
    "<u>Evaluation:</u><br>\n",
    "loss:  -76669.99157242064<br>\n",
    "accuracy:  0.11547619104385376\n",
    "\n",
    "\n",
    "<b>3-with Dropout and SGD = 0,001</b><br>\n",
    "<u>Training:</u> <br>\n",
    "Epoch 100/100 20580/20580 [==============================] - 1s 33us/step - loss: -5331.8802 - accuracy: 0.1103\n",
    "\n",
    "<u>Evaluation:</u><br>\n",
    "loss:  -5388.151646648243<br>\n",
    "accuracy:  0.10997732728719711\n",
    "\n",
    "\n",
    "<b>4-With Batch Normalization</b><br>\n",
    "<u>-Training: </u><br>\n",
    "Epoch 100/100 14406/14406 [==============================] - 1s 36us/step - loss: -3865.8678 - accuracy: 0.1092\n",
    "\n",
    "<u>-Evaluation:</u><br>\n",
    "loss:  -3879.7241630887847<br>\n",
    "accuracy:  0.11305474489927292"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
