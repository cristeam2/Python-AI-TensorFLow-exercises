{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on: https://github.com/buomsoo-kim/Easy-deep-learning-with-Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of MLP\n",
    "- Objective: create vanilla neural networks (i.e., Multilayer perceptrons) for simple regression/classification tasks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Structures\n",
    "- Each MLP model is consisted of one input layer, several hidden layers, and one output layer\n",
    "- Number of neurons in each layer is not limited\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\" style=\"width: 300px\"/>\n",
    "<br>\n",
    "<center>**MLP with one hidden layer**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: 4\n",
    "- Number of output neurons: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" style=\"width: 500px\"/>\n",
    "<br>\n",
    "<center>**MLP with two hidden layers**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: (4, 4)\n",
    "- Number of output neurons: 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for Regression tasks\n",
    "- When the target (**y**) is continuous (real)\n",
    "- For loss function and evaluation metric, mean squared error (MSE) is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5cead47b4909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mboston_housing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Boston housing dataset has total 506 data instances (404 training & 102 test)\n",
    "- 13 attributes (features) to predict \"the median values of the houses at a location\"\n",
    "- Doc: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#data_path='week3_exam_dataset_train.csv'\n",
    "#data = np.loadtxt(data_path, delimiter=',', skiprows=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Keras model object can be created with Sequential class\n",
    "- At the outset, the model is empty per se. It is completed by **'adding'** additional layers and compilation\n",
    "- Doc: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daniel\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 622\n",
      "Trainable params: 622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daniel\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 385.4242 - mean_squared_error: 385.4242\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 30us/step - loss: 96.1017 - mean_squared_error: 96.1017\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.5624 - mean_squared_error: 85.5624\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 84.8892 - mean_squared_error: 84.8892\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.2516 - mean_squared_error: 85.2516\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.1707 - mean_squared_error: 85.1707\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.9869 - mean_squared_error: 85.9869\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0725 - mean_squared_error: 85.0725\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.8818 - mean_squared_error: 84.8818\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.8649 - mean_squared_error: 84.8649\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 84.8450 - mean_squared_error: 84.8450\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 87.6975 - mean_squared_error: 87.6975\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0814 - mean_squared_error: 85.0814\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.8549 - mean_squared_error: 84.8549\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 84.8168 - mean_squared_error: 84.8168\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.7339 - mean_squared_error: 85.7339\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.9795 - mean_squared_error: 84.9795\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.3330 - mean_squared_error: 85.3330\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 84.7287 - mean_squared_error: 84.7287\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.9953 - mean_squared_error: 84.9953\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 30us/step - loss: 85.2005 - mean_squared_error: 85.2005\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 87.4597 - mean_squared_error: 87.4597\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.7200 - mean_squared_error: 84.7200\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.1759 - mean_squared_error: 85.1759\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.6760 - mean_squared_error: 85.6760\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.7801 - mean_squared_error: 84.7801\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.9256 - mean_squared_error: 84.9256\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.3066 - mean_squared_error: 85.3066\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 84.6834 - mean_squared_error: 84.6834\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 84.9257 - mean_squared_error: 84.9257\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.1908 - mean_squared_error: 85.1908\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0595 - mean_squared_error: 85.0595\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.8472 - mean_squared_error: 84.8472\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 84.7067 - mean_squared_error: 84.7067\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 84.9353 - mean_squared_error: 84.9353\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.3146 - mean_squared_error: 85.3146\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.2318 - mean_squared_error: 85.2318\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.8280 - mean_squared_error: 85.8280\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 86.1566 - mean_squared_error: 86.1566\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.3841 - mean_squared_error: 85.3841\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 84.9163 - mean_squared_error: 84.9163\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.8083 - mean_squared_error: 85.8083\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.3153 - mean_squared_error: 85.3153\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - ETA: 0s - loss: 96.1334 - mean_squared_error: 96.13 - 0s 25us/step - loss: 85.0616 - mean_squared_error: 85.0616\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.1183 - mean_squared_error: 85.1183\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.2005 - mean_squared_error: 85.2005\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.3538 - mean_squared_error: 85.3538\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.0292 - mean_squared_error: 85.0292\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0059 - mean_squared_error: 85.0059\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 86.0155 - mean_squared_error: 86.0155\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.7618 - mean_squared_error: 84.7618\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.5058 - mean_squared_error: 85.5058\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.8724 - mean_squared_error: 84.8724\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 30us/step - loss: 85.0834 - mean_squared_error: 85.0834\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 86.9928 - mean_squared_error: 86.9928\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.7276 - mean_squared_error: 84.7276\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0388 - mean_squared_error: 85.0388\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 86.2870 - mean_squared_error: 86.2870\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.8135 - mean_squared_error: 84.8135\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.1962 - mean_squared_error: 85.1962\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.2153 - mean_squared_error: 85.2153\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.3011 - mean_squared_error: 85.3011\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.7592 - mean_squared_error: 85.7592\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.7286 - mean_squared_error: 85.7286\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.8015 - mean_squared_error: 84.8015\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.3277 - mean_squared_error: 85.3277\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0930 - mean_squared_error: 85.0930\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.9277 - mean_squared_error: 84.9277\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0696 - mean_squared_error: 85.0696\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.9966 - mean_squared_error: 84.9966\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.1461 - mean_squared_error: 85.1461\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 84.9787 - mean_squared_error: 84.9787\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.5027 - mean_squared_error: 85.5027\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.8605 - mean_squared_error: 84.8605\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.1596 - mean_squared_error: 85.1596\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0755 - mean_squared_error: 85.0755\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.9410 - mean_squared_error: 84.9410\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.4106 - mean_squared_error: 85.4106\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.5117 - mean_squared_error: 85.5117\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.8355 - mean_squared_error: 85.8355\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 84.9862 - mean_squared_error: 84.9862\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.2702 - mean_squared_error: 85.2702\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.4443 - mean_squared_error: 85.4443\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.5600 - mean_squared_error: 85.5600\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0579 - mean_squared_error: 85.0579\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 84.8292 - mean_squared_error: 84.8292\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 85.1179 - mean_squared_error: 85.1179\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 84.7832 - mean_squared_error: 84.7832\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.2689 - mean_squared_error: 85.2689\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.7791 - mean_squared_error: 84.7791\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0326 - mean_squared_error: 85.0326\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.1718 - mean_squared_error: 85.1718\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 85.0160 - mean_squared_error: 85.0160\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.0949 - mean_squared_error: 85.0949\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 84.9866 - mean_squared_error: 84.9866\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 25us/step - loss: 86.1239 - mean_squared_error: 86.1239\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 84.9723 - mean_squared_error: 84.9723\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.0524 - mean_squared_error: 85.0524\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 27us/step - loss: 84.7371 - mean_squared_error: 84.7371\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 22us/step - loss: 85.1204 - mean_squared_error: 85.1204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe3d4e80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 735us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_squared_error']\n",
      "[83.25924533021217, 83.25924533021217]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  83.25924533021217\n",
      "mse:  83.25924533021217\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for classification tasks\n",
    "- When the target (**y**) is discrete (categorical)\n",
    "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': 'Breast Cancer Wisconsin (Diagnostic) Database\\n=============================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\nReferences\\n----------\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.\\n', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')}\n"
     ]
    }
   ],
   "source": [
    "whole_data = load_breast_cancer()\n",
    "print(whole_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = whole_data.data\n",
    "y_data = whole_data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
    "- 30 attributes (features) to predict the binary class (M/B)\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "#print(X_train)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Same with regression model at the outset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- It should be noted that as this is a classification problem, sigmoid layer (softmax for multi-class problems) should be added\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daniel\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (30,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daniel\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 0.6757 - acc: 0.6055\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6750 - acc: 0.6055\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6740 - acc: 0.6055\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.6732 - acc: 0.6055\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6728 - acc: 0.6055\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6725 - acc: 0.6055\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6722 - acc: 0.6055\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 0.6720 - acc: 0.6055\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6718 - acc: 0.6055\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.6716 - acc: 0.6055\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6714 - acc: 0.6055\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6714 - acc: 0.6055\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.6713 - acc: 0.6055\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6712 - acc: 0.6055\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6711 - acc: 0.6055\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.6711 - acc: 0.6055\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6711 - acc: 0.6055\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6710 - acc: 0.6055\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.7279 - acc: 0.480 - 0s 50us/step - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 63us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 63us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 23us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 68us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 65us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 28us/step - loss: 0.6710 - acc: 0.6055\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 63us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 25us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 30us/step - loss: 0.6707 - acc: 0.6055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe430d68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 561us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.6394622329382869, 0.6783625724022848]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.638706070638\n",
      "accuracy:  0.678362572402\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('accuracy: ', results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
